{
  "active_panel": "Inspector",
  "file_tree": [
    {
      "name": "large_file.py",
      "path": "large_file.py",
      "is_dir": false,
      "git_status": "M",
      "children": []
    }
  ],
  "selected_file_path": "large_file.py",
  "search_query": "",
  "in_search_mode": false,
  "commit_list": [
    {
      "hash": "abc123def456abc123def456abc123def456abc1",
      "short_hash": "abc123d",
      "author": "Developer One",
      "date": "5 minutes ago",
      "subject": "Optimize performance for large datasets"
    }
  ],
  "selected_commit_index": 0,
  "current_content": [
    "import pandas as pd",
    "import numpy as np",
    "",
    "def process_large_dataset(data):",
    "    # Processing large amounts of data",
    "    result = data.groupby('category').agg({",
    "        'value': ['mean', 'std', 'count']",
    "    })",
    "    return result"
  ],
  "cursor_line": 4,
  "cursor_column": 8,
  "inspector_scroll_vertical": 0,
  "inspector_scroll_horizontal": 0,
  "show_diff_view": false,
  "status_message": "Searching for next change...",
  "is_loading": true
}